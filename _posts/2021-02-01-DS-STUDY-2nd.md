---
layout: post
title: "따라 하며 배우는 데이터 과학 2"
date: 2021-02-01 23:00:00 +0900
author: JunYoung
categories: CS ML
tags: Machine_Learning Data_Science R
math: true
---

# Ch7

데이터의 종류에 따른 기본적인 분석 기법들을 설명한다.

## 수량형 변수

### 시각화를 해본다

### 요약 통계량을 계산해본다

### `qqplot(), qqline()`으로 데이터의 정규성을 검사한다.

### `t.test()` 로 일변량 t-검정과 신뢰구간을 구할 수 있다.

예시

```r
t.test(hwy, mu = mu0, alternative = "greater")
```

### 이상점이 있는지 살피고 이상점이 있는 경우 로버스트 통계량을 계산해본다.

`boxplot()`으로 이상점을 찾을 수 있다.
`boxplot()`에서 이상점은 $$\left[Q1 - 1.5 \times IQR, \; Q3 + 1.5 \times IQR\right] \qquad (IQR = Q3 - Q1)$$ 의 바깥에 있는 점을 말한다.

로버스트 통계 방법은 이상점의 영향을 적게 받는 방법들이다. 기본적으로는 평균 대신 중앙값,
표준편차 대신 MAD(median absolute deviance)를 사용하면 된다.

## 성공-실패 범주형 변수의 분석

### `binom.test()`로 모비율에 대한 검정을 할 수 있다.

예시)

```r
binom.test(x = length(x[x == 'yes']), n = length(x), p = 0.5, alternative = "two.sided")
```

`t.test()`와 문법이 크게 다르지 않다.

### 표본 크기에 주의하자.

같은 표본비율이더라도 $$n$$이 커지면 오차한계(= 신뢰구간의 크기의 절반)은 $$ \displaystyle\frac{1}{\sqrt{n}}$$
에 비례하여 줄어든다.

## 수량형 x, 수량형 y

### 산점도

산점도를 통해 관계가 선형인지, 강한지 약한지, 이상치가 있는지 등을 살필 수 있다.
중복값이 많을 때는 `jitter()`를 쓰면 점을 흩어줄 수 있다.
데이터가 너무 많을 때는 `alpha=`옵션을 사용하거나 표본화한다.

### 상관계수를 계산한다

상관계수 계산의 기본 옵션은 선형 관계가 얼마나 강한지 측정하는 pearson상관계수이다.

$$
\displaystyle r = \frac {\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 }\sqrt{\sum (y_i - \bar{y})^2}}
$$

`method=`인자로 kendall 상관계수와 spearman 상관계수를 계산할 수 있다.
kendall의 $$\tau$$ 는 다음과 같다.

$$
\displaystyle \tau = \frac{\textrm{concordant 관측치 개수} - \textrm{disconcordant 관측치 개수}}{\binom{n}{2}}
$$

spearman의 $$\rho$$는 $$x_i, y_i$$를 순위값으로 바꿔준 후 pearson 상관계수를 계산한 값이다.

### 선형회귀 모형 적합

#### 선형회귀 모형

$$
Y_i \sim \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{p}x_{ip} + \epsilon_{i}, \; \epsilon_{i}
\sim _{iid} N(0, \sigma^2)
$$

$$
    \displaystyle \left\Vert y - X \beta \right\Vert
$$

를 최소로 하는 $$\beta$$를 찾으면 된다.

$$
\left( y \in \mathbb{R}^n, X \in \textrm{Mat}_{n \times (p + 1)} (\mathbb{R})\right)
$$

$$
    \left(\mathbf{x}_1 = (1 \;1 \cdots 1)^{t}, \mathbf{x}_{i + 1} =  (x_{1i} \; x_{2i} \cdots x_{ni})^t \right)
$$

즉 $$y$$를 $$X$$의 열벡터들로 생성되는 공간에 사영한 것이 $$X\beta$$이다.

$$
 \left( \textrm{참고}: X \mathbf{e}_i = \mathbf{x}_i  \textrm{ 이므로, }
X\mathbf{v} \; (\mathbf{v}\in \mathbb{R}^n) \textrm{ 의 집합은 } X \textrm{의 열공간이다.} \right)
$$

따라서, $$ X^t y = X^t X \hat{\beta} $$ 이므로, $$\hat{\beta} = (X^t X)^{-1} X^{t}y$$이다.

또한 $$ \hat{y} = X \hat{\beta} = X (X^t X)^{-1} X^{t}y = H y$$ 이다.
이때 $$H$$의 대각성분들이 leverage이다. leverage의 값이 크면 $$y_i$$갑의 작은 변화에도
$$\hat{y_i}$$가 $$y_i$$방향으로 더 많이 끌려가게 된다.

#### 적합도 검정

$$
\textrm{SST} = \sum (y_i - \bar{y}),\;
\textrm{SSR} = \sum (\hat{y_i} - \bar{y})^2,\; \textrm{SSE} = \sum (y_i - \hat{y_i})^2
$$

SSR은 회귀분석 모형으로 설명되는 반응변수의 변동을, SSE는 회귀분석 모형으로 설명되지 않는
반응변수의 변동을 나타낸다.
$$ \displaystyle R^2 = \frac{\textrm{SSR}}{\textrm{SST}}$$ 는 반응변수의 총 변동 중
얼마만큼이 선형 모형으로 설명되는지를 나타낸다. 즉 이 값이 높으면 설명력이 좋다.

이 값은 모형의 반응변수 개수가 많아질수록 증가한다는 것이 증명되어 있으므로, Adjusted R-squared
값을 사용한다.

$$
\displaystyle \textrm{Adjusted } R^2 = 1 - (1-R^2) \frac{ n - 1}{n - p - 1}
$$

#### 선형회귀 모형의 가정

선형 회귀 모형은 몇 가지 가정이 필요하다, 이를 충족시키는지를 잘 따져 봐야 한다.

1. $$x$$와 $$y$$의 관계가 선형이다.
2. 잔차의 분포가 독립이다.
3. 잔차의 분포가 동일하다.
4. 잔차의 분포가 $$N(0, \sigma^2)$$

1번은 산점도를 그리고 상관계수를 계산함으로써 쉽게 따질 수 있다.

2, 3, 4를 확인하기 위해서는 통계학 시간에 배운 대로 잔차의 분포를 시각화하여
살펴 봐야 한다.

#### 로버스트 선형회귀분석

앞서 수량형 변수 분석에서와 마찬가지로, 이상치가 있을 경우에는 로버스트 통계 방법을 사용하는
것이 유용할 수 있다.

<a href = "https://goo.gl/uttsPB">CRAN의 로버스트 통계 task view</a>

`MASS::lqs()` 함수는 데이터 중 좋은 관측치만 적합에 사용한다.

```r
library(MASS)
set.seed(123)
lqs(stack.loss ~ ., data = stackloss)
lm(stack.loss ~ ., data = stackloss)
```

### 비선형/비모수적 방법

선형회귀분석은 선형 관계만 모델링할수 있다.
비선형적인 관계를 추정하기 위해서는 다양한 방법이 있다.
대표적인 방법은 평활법이다.

$$
y_i = f(x_i) + \epsilon_i, \epsilon_i \sim_{iid} (0, \sigma^2)
$$

$$f(x)$$는 매끄럽기만 하면 되며, 잔차 또한 정규분포일 필요가 없다.
예시) LOESS를 사용한 평활법 계산

```r
plot(hwy ~ displ, data = mpg)
mpg_lo <- loess(hwy ~ displ, data = mpg)
mpg_lo
summary(mpg_lo)

ggplot(mpg, aes(displ, hwy)) + geom_point() + geom_smooth()
```

## 범주형 x, 수량형 y

### 병렬상자그림을 이용하여 데이터 시각화

### `lm()`함수로 ANOVA적합

ANOVA 모형은 다음과 같다.

$$
Y_{ij} = \beta_{i} + \epsilon_{ij}, \;\epsilon_{ij} \sim _{iid} N(0, \sigma^2)
$$

혹은 각 원소가 $$0$$ 또는 $$1$$인 $$ n \times p $$행렬 $$ X$$를 이용하면

$$
Y_i = \beta_0 + \beta_{1}x_{i1} + \cdots + \beta_p x_{ip} +\epsilon_{i},\;
\epsilon_{i} \sim _{iid} N(0, \sigma^2)
$$

로 쓸 수 있다. (이러한 행렬을 디자인행렬(design matrix)라 한다.)

수학적으로 같은 모형이므로 똑같이 `lm()`함수를 써서 적합할 수 있다.

### `plot.lm()`으로 잔차의 분포를 시각화

## 수량형 x, 범주형 y (성공 - 실패)

### x와 (jitter된) y의 산점도를 그려보고, y변수의 그룹별로 x변수의 병렬상자그림을 그려본다.

### `glm()`함수로 일반화 선형 모형을 적합한다.

성공-실패 $$y$$변수와 수량형 $$x$$변수는

$$
    Y \sim Bernoulli(p),\; \Pr(Y = 1 \vert x) = \mu(x)
$$

와 같이 생각할 수 있다.
여기서 적당한 transformation $$ f: [0, 1] \rightarrow (-\infty, \infty)$$가 존재하여
$$ f(y_i) $$를 선형 모델으로 적합한 후, 다시 역함수를 씌워 $$y$$를 모델링하는 것이 기본
아이디어이다.

보통 `logit()` 함수를 사용한다.
$$ \displaystyle \textrm{logit}(\mu) = \log \left( \frac{ \mu} {1 - \mu}\right) = x \beta$$이다.
$$\beta$$의 추정값은 최대우도법을 통하여 계산하게 된다.

이제 역함수인 logistic함수를 사용하여 주어진 $$x$$값에 대한 성공확률의 추정값을 계산할 수 있다.
$$ \displaystyle \textrm{logistic}(\eta) = \frac{1}{1 + \exp(- \eta) }$$이다.

최대우도법 관련해서는 잘 몰라서 이부분은 더 공부해야겠다...

### `plot.glm()`으로 잔차의 분포를 살펴본다.
